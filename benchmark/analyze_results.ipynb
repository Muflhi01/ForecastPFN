{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e56e6541-a3f4-4e53-b8dc-17505940ac92",
   "metadata": {},
   "source": [
    "This notebook produces the main data from the paper:\n",
    "# ForecastPFN: Synthetically-Trained Zero-Shot Forecasting\n",
    "By: Samuel Dooley, Gurnoor Singh Khurana, Chirag Mohapatra, Siddartha Naidu, Colin White\n",
    "\n",
    "The CSVs which can be used to reproduce the tables can be downloaded [here](https://drive.google.com/file/d/1oa9FlY6WQojlN4nx8ZGmo8Zbfc5QG-bd/view?usp=sharing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f5eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bf85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0293b2-f4d5-4dda-a5a3-c2b8fdd64f85",
   "metadata": {},
   "source": [
    "# Produce Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45919d54-bce3-4110-8a6e-a7920316f318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('benchmark.csv')\n",
    "fifty = df[df['Train Budget'] == 50].groupby('Model').apply(lambda x: x.groupby('Dataset').mean()['mse']).round(3).style.apply(lambda col: ['font-weight:bold' if x==col.min() else '' for x in col])\n",
    "# print(fifty.to_latex().replace('\\\\font-weightbold ', '\\\\textbf{'))\n",
    "fifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b52c2c-e911-4dcb-9c98-9a3011f14bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fhund = df[df['Train Budget'] == 500].groupby('Model').apply(lambda x: x.groupby('Dataset').mean()['mse']).round(3).style.apply(lambda col: ['font-weight:bold' if x==col.min() else '' for x in col])\n",
    "# print(fhund.to_latex().replace('\\\\font-weightbold ', '\\\\textbf{'))\n",
    "fhund"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33061b0d-4429-4754-824c-362c5ddc987c",
   "metadata": {},
   "source": [
    "# Produce Figures 3 and 4\n",
    "and associated figures for other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5033e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine\n",
    "from plotnine import *\n",
    "fpfn_theme = plotnine.themes.theme(\n",
    "    legend_position=\"bottom\",\n",
    "    legend_box_spacing=.55,\n",
    "    axis_text_x=element_text(rotation=45, hjust=1)) + theme_minimal()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "colors = {'Informer': '#7fc97f',\n",
    "          'Arima': '#beaed4',\n",
    "          'Meta-N-BEATS': '#bb2299',\n",
    "          'ForecastPFN': 'Black',\n",
    "          'ForecastPFN_20230502-140223': 'Pink',\n",
    "          'Autoformer': '#386cb0',\n",
    "          'FEDformer': '#f0270f',\n",
    "          'Prophet': '#bf5b16',\n",
    "          'Transformer': '#fdc086',\n",
    "          'Mean': '#287068',\n",
    "          'Last': '#C12FDD',\n",
    "          'SeasonalNaive': '#008000'\n",
    "         }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999475df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Wins by Prediction Length\n",
    "metric_wins_pred_agg = pd.read_csv('metric_wins_pred_agg.csv', index_col=0)\n",
    "metric_wins_pred_agg['Prediction Length'] = metric_wins_pred_agg['Prediction Length'].astype('int')\n",
    "metric_wins_pred_agg['Train Budget'] = metric_wins_pred_agg['Train Budget'].astype('int')\n",
    "\n",
    "\n",
    "for metric, group in metric_wins_pred_agg.groupby('metric'):\n",
    "    p = (ggplot(group)\n",
    "         + aes(x='Prediction Length', y='Wins', color='Model')\n",
    "         + geom_line()\n",
    "         + geom_ribbon(aes(ymin=f'Wins_low', ymax=f'Wins_upper',\n",
    "                           fill='Model'), alpha=.15, outline_type='upper', show_legend=False)\n",
    "         + facet_grid('~Train Budget')\n",
    "         + scale_color_manual(values=colors)\n",
    "         + scale_fill_manual(values=colors)\n",
    "         + fpfn_theme\n",
    "         + labs(title=f'{metric} Wins per Prediction Length By Data Budget (50 to 500)')\n",
    "         + ylab(f'{metric} Wins')\n",
    "         + geom_point(aes(shape='Model'))\n",
    "         + theme(figure_size=(15, 5))\n",
    "         + theme(\n",
    "               legend_direction='horizontal',\n",
    "               legend_position=(.5,.04),\n",
    "               legend_title=element_blank(),\n",
    "               legend_box_spacing=.4,\n",
    "               plot_title = element_text(hjust = 0.5, size=20),\n",
    "               axis_text_x=element_text(size=14),\n",
    "               axis_text_y=element_text(size=14),\n",
    "               axis_title_x=element_text(size=16),\n",
    "               axis_title_y=element_text(size=16),\n",
    "               strip_text_x=element_text(size=14),\n",
    "               legend_text=element_text(size=14),\n",
    "          )\n",
    "         + guides(fill=guide_legend(nrow=1), color=guide_legend(nrow=1))\n",
    "    )\n",
    "    print(p)\n",
    "#     p.save(f'figures/{metric}_wins_predlen_legend_error.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be615941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Mean Rank vs Prediction Length\n",
    "rank_pred_agg = pd.read_csv('rank_pred_agg.csv', index_col=0)\n",
    "rank_pred_agg['Prediction Length'] = rank_pred_agg['Prediction Length'].astype(\n",
    "    'int')\n",
    "rank_pred_agg['Train Budget'] = rank_pred_agg['Train Budget'].astype(\n",
    "    'int')\n",
    "\n",
    "\n",
    "for metric, group in rank_pred_agg.groupby('metric'):\n",
    "    p = (ggplot(group)\n",
    "         + aes(x='Prediction Length', y='Rank', color='Model')\n",
    "         + geom_line()\n",
    "         + geom_ribbon(aes(ymin=f'Rank_low', ymax=f'Rank_upper',\n",
    "                           fill='Model'), alpha=.15, outline_type='upper', show_legend=False)\n",
    "         + facet_grid('~Train Budget')\n",
    "         + scale_color_manual(values=colors)\n",
    "         + scale_fill_manual(values=colors)\n",
    "         + fpfn_theme\n",
    "         + labs(title=f'Mean {metric} Rank per Prediction Length By Data Budget (50 to 500)')\n",
    "         + ylab(f'Mean {metric} Rank')\n",
    "         + geom_point(aes(shape='Model'))\n",
    "         + theme(figure_size=(15, 5))\n",
    "         + theme(\n",
    "               legend_direction='horizontal',\n",
    "               legend_position=(.5,.04),\n",
    "               legend_title=element_blank(),\n",
    "               legend_box_spacing=.4,\n",
    "               plot_title = element_text(hjust = 0.5, size=20),\n",
    "               axis_text_x=element_text(size=14),\n",
    "               axis_text_y=element_text(size=14),\n",
    "               axis_title_x=element_text(size=16),\n",
    "               axis_title_y=element_text(size=16),\n",
    "               strip_text_x=element_text(size=14),\n",
    "               legend_text=element_text(size=14),\n",
    "    )\n",
    "        + guides(fill=guide_legend(nrow=1), color=guide_legend(nrow=1))\n",
    "    )\n",
    "    print(p)\n",
    "#     p.save(f'figures/mean_{metric}_rank_predlen_legend_error.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ec4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Wins vs. Data Budgets\n",
    "metric_wins_train_agg = pd.read_csv('metric_wins_train_agg.csv', index_col=0)\n",
    "\n",
    "for metric, group in metric_wins_train_agg.groupby('metric'):\n",
    "    p = (ggplot(group)\n",
    "        + aes(x='Train Budget', y='Wins', color='Model')\n",
    "        + geom_line()\n",
    "        + geom_ribbon(aes(ymin=f'Wins_low', ymax=f'Wins_upper',\n",
    "                    fill='Model'), alpha=.15, outline_type='upper', show_legend=False)\n",
    "        + scale_color_manual(values=colors)\n",
    "        + scale_fill_manual(values=colors)\n",
    "        + fpfn_theme\n",
    "        + labs(\n",
    "            title=f'Number of total {metric} Wins per Data Budget',\n",
    "            x=\"Data Budget\"\n",
    "              )\n",
    "        + ylab(f'{metric} Wins')\n",
    "        + geom_point(aes(shape='Model'))\n",
    "        # + theme(legend_position=\"none\")\n",
    "        + scale_x_continuous(trans='log10')\n",
    "        )\n",
    "    print(p)\n",
    "#     p.save(f'figures/{metric}_wins_trainbudget_error.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e47929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Wins vs. Time Budgets\n",
    "metric_wins_time_agg = pd.read_csv('metric_wins_time_agg.csv', index_col=0)\n",
    "\n",
    "for metric, group in metric_wins_time_agg.groupby('metric'):\n",
    "    p = (ggplot(group)\n",
    "         + aes(x='Time Budget', y='Wins', color='Model')\n",
    "         + geom_line()\n",
    "         + geom_ribbon(aes(ymin=f'Wins_low', ymax=f'Wins_upper',\n",
    "                           fill='Model'), alpha=.15, outline_type='upper', show_legend=False)\n",
    "         + scale_color_manual(values=colors)\n",
    "         + scale_fill_manual(values=colors)\n",
    "         + fpfn_theme\n",
    "         + labs(title=f'Number of total {metric} Wins per Time Budget')\n",
    "         + ylab(f'{metric} Wins')\n",
    "         + geom_point(aes(shape='Model'))\n",
    "         + theme(\n",
    "#                  legend_position=\"none\",\n",
    "                 plot_title = element_text(hjust = 0.5)\n",
    "                )\n",
    "         + scale_x_continuous(trans='log10')\n",
    "#          + theme(figure_size=(4.8, 4.8))\n",
    "         )\n",
    "    print(p)\n",
    "#     p.save(f'figures/{metric}_wins_timebudget_error.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Mean Rank vs. Data Budgets\n",
    "rank_train_agg = pd.read_csv('rank_train_agg.csv', index_col=0)\n",
    "\n",
    "for metric, group in rank_train_agg.groupby('metric'):\n",
    "    p = (ggplot(group)\n",
    "         + aes(x='Train Budget', y='Rank', color='Model')\n",
    "         + geom_line()\n",
    "         + geom_ribbon(aes(ymin=f'Rank_low', ymax=f'Rank_upper',\n",
    "                           fill='Model'), alpha=.15, outline_type='upper', show_legend=False)\n",
    "         + scale_color_manual(values=colors)\n",
    "         + scale_fill_manual(values=colors)\n",
    "         + fpfn_theme\n",
    "         + labs(title=f'Mean {metric} Rank per Data Budget',\n",
    "                x=\"Data Budget\"\n",
    "               )\n",
    "         + ylab(f'Mean {metric} Rank')\n",
    "         + geom_point(aes(shape='Model'))\n",
    "         + theme(legend_position=\"none\",\n",
    "                plot_title = element_text(hjust = 0.5),\n",
    "                )\n",
    "         + scale_x_continuous(trans='log10')\n",
    "         + theme(figure_size=(4.8, 4.8))\n",
    "         )\n",
    "    print(p)\n",
    "#     p.save(f'figures/mean_{metric}_rank_trainbudget_error.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937b02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots Mean Rank vs. Time Budgets\n",
    "rank_time_agg = pd.read_csv('rank_time_agg.csv', index_col=0)\n",
    "\n",
    "for metric, group in rank_time_agg.groupby('metric'):\n",
    "    p = (ggplot(group)\n",
    "         + aes(x='Time Budget', y='Rank', color='Model')\n",
    "         + geom_line()\n",
    "         + geom_ribbon(aes(ymin=f'Rank_low', ymax=f'Rank_upper',\n",
    "                           fill='Model'), alpha=.15, outline_type='upper', show_legend=False)\n",
    "         + scale_color_manual(values=colors)\n",
    "         + scale_fill_manual(values=colors)\n",
    "         + fpfn_theme\n",
    "         + labs(title=f'Mean {metric} Rank per Time Budget')\n",
    "         + ylab(f'Mean {metric} Rank')\n",
    "         + geom_point(aes(shape='Model'))\n",
    "         + theme(legend_position=\"none\",\n",
    "                plot_title = element_text(hjust = 0.5),               \n",
    "                )\n",
    "         + scale_x_continuous(trans='log10')\n",
    "         + theme(figure_size=(4.8, 4.8))\n",
    "         )\n",
    "    print(p)\n",
    "#     p.save(f'figures/mean_{metric}_rank_timebudget_error.pdf')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
